{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c51f30a-72ce-4dc7-905c-9f73815b2999",
   "metadata": {},
   "source": [
    "**READ PACKAGES**  ->  **LOAD CLASSES**  ->  **LOAD MODEL**  ->  **RUN VIDEO OR LIVE STREAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741b9e2-3e4d-413a-ae87-e86020e319c6",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2a83d-c088-4235-85c4-154fc5c1af67",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82436b-a375-4dcd-ba54-1e9b5afc54a4",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b21787-60eb-4f90-91b6-682d712e23cf",
   "metadata": {},
   "source": [
    "**IMPORTING THE PACKAGES AND DEPEDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd233e64-d881-4e1c-a1a7-5d4ecf4a9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from support_files.detection import detect_people\n",
    "from support_files import social_distancing_config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9a441-f81c-4b1e-9511-03a0fb75875f",
   "metadata": {},
   "source": [
    "**LOADING THE CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee151c95-819d-4385-a5b1-c846587c486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# load the COCO class labels our YOLO model was trained on\n",
    "labelsPath = os.path.sep.join([config.MODEL_PATH, \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4e7e5-e53f-4f88-8d73-6f8719b61ed4",
   "metadata": {},
   "source": [
    "**LOADING OUR MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d68a8638-4e69-43c3-bbbf-ab37fe4c5943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n"
     ]
    }
   ],
   "source": [
    "# derive the paths to the YOLO weights and model configuration\n",
    "weightsPath = os.path.sep.join([config.MODEL_PATH, \"yolov3.weights\"])\n",
    "configPath = os.path.sep.join([config.MODEL_PATH, \"yolov3.cfg\"])\n",
    "\n",
    "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a326b7-cf85-4d38-9cc7-5c78f9417205",
   "metadata": {},
   "source": [
    "**DEFINING THE RUN VIDEO FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d9be239-1f2f-4f54-804a-b1b221ac47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video(vs):\n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        # read the next frame from the file\n",
    "        (grabbed, frame) = vs.read()\n",
    "\n",
    "        # if the frame was not grabbed, then we have reached the end of the stream\n",
    "        if not grabbed:\n",
    "            break\n",
    "\n",
    "        # resize the frame and then detect people (and only people) in it\n",
    "        frame = imutils.resize(frame, width=550)\n",
    "        results = detect_people(frame, net, ln,personIdx=LABELS.index(\"person\"))\n",
    "\n",
    "        # initialize the set of indexes that violate the minimum social distance\n",
    "        violate = set()\n",
    "\n",
    "        # ensure there are *at least* two people detections (required in order to compute our pairwise distance maps)\n",
    "        if len(results) >= 2:\n",
    "            # extract all centroids from the results and compute the Euclidean distances between all pairs of the centroids\n",
    "            centroids = np.array([r[2] for r in results])\n",
    "            D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "            # loop over the upper triangular of the distance matrix\n",
    "            for i in range(0, D.shape[0]):\n",
    "                for j in range(i + 1, D.shape[1]):\n",
    "                    # check to see if the distance between any two centroid pairs is less than the configured number of pixels\n",
    "                    if D[i, j] < config.MIN_DISTANCE:\n",
    "                        # update our violation set with the indexes of the centroid pairs\n",
    "                        violate.add(i)\n",
    "                        violate.add(j)\n",
    "\n",
    "        # loop over the results\n",
    "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "            # extract the bounding box and centroid coordinates, then initialize the color of the annotation\n",
    "            (startX, startY, endX, endY) = bbox\n",
    "            (cX, cY) = centroid\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            # if the index pair exists within the violation set, then update the color\n",
    "            if i in violate:\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            # draw (1) a bounding box around the person and (2) the centroid coordinates of the person,\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "            cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "        # draw the total number of social distancing violations on the output frame\n",
    "        text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "        cv2.putText(frame, text, (10, frame.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ed155-091e-4f3b-a194-7d4baf4f2263",
   "metadata": {},
   "source": [
    "**INITIALISE CAMERA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa2f01f-c4cd-4f94-b495-1cc59aaaca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(\"demo_files/demo1.gif\")\n",
    "run_video(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75e5cf0b-7853-4444-8c6a-45db63f23dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(\"demo_files/demo2.gif\")\n",
    "run_video(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94b7e2b3-0b96-4317-a574-45d62dcc5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(\"demo_files/demo3.gif\")\n",
    "run_video(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e303c7fa-d04e-47eb-b94d-e76719c50ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(\"demo_files/demo4.gif\")\n",
    "run_video(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb487d8b-a7e9-44a9-95b1-62081abced96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(\"demo_files/demo5.gif\")\n",
    "run_video(vs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
